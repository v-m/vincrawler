#!/usr/bin/env python
# -*- encoding: utf8 -*-

"""
Crawler executable
Author: Vincenzo Musco (http://www.vmusco.com)
Date: 9 January 2019
"""

__author__ = "Vincenzo Musco (http://www.vmusco.com)"
__date__ = "9 January 2019"

import argparse
import sys
from vmusco import __VERSION__
from vmusco.crawler import Crawler, VerboseLogger

DEFAULT_AGENT = "vincrawler-bot/{}".format(__VERSION__)

if __name__ == '__main__':
    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument("url", type=str, help="base url to crawl")
    arg_parser.add_argument("-a", "--useragent", type=str, default=DEFAULT_AGENT,
                            help="user agent to use (default: {})".format(DEFAULT_AGENT))
    arg_parser.add_argument("-R", "--robot", type=str, default="robots.txt", help="robots file (default: robots.txt)")
    arg_parser.add_argument("-t", "--tasks", type=int, default=2, help="number of tasks per unit of time (default: read"
                                                                       " from robots.txt or 2)")
    arg_parser.add_argument("-u", "--unit", type=int, default=1, help="the unit of time (default: read from robots.txt"
                                                                      " or 1 sec)")
    arg_parser.add_argument("-q", "--ignorequeries", action="store_true", help="ignore queries part in url")
    arg_parser.add_argument("-v", "--verbose", action="count", help="verbosity level", default=0)

    args = arg_parser.parse_args()

    print("VinCrawler {}.".format(__VERSION__), file=sys.stderr)
    crawler = Crawler(args.url, args.useragent, args.robot, args.tasks, args.unit, args.ignorequeries)
    logger = VerboseLogger(3)
    logger.set_verbosity(args.verbose)
    crawler.set_logger(logger)
    crawler.start()

    print("\n".join(crawler.result()))
